{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNwrP0PdnL7G"
      },
      "source": [
        "# Librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wR7VaFQV6o5m"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import sys\n",
        "import unicodedata\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import tokenize\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk import ngrams\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "import collections\n",
        "from nltk.stem import WordNetLemmatizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnWb5ciYVKJv",
        "outputId": "cecf1dee-88ee-4b58-84e2-c1f9395783d4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\te512362\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\te512362\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LostjXxMeBS"
      },
      "source": [
        "# Pre-procesamiento de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pkWdHtze6l9s"
      },
      "outputs": [],
      "source": [
        "#Creamos una variable df con el dataset\n",
        "df = pd.read_csv(\"haha_2021_train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8q1WuYVGGe1c"
      },
      "outputs": [],
      "source": [
        "df.drop([\"votes_no\",\"votes_1\", \"votes_2\", \"votes_3\", \"votes_4\", \"votes_5\",\"humor_mechanism\"],\n",
        "          axis=1,\n",
        "          inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5-fqopZH08r1",
        "outputId": "d007cca1-4fdc-41dd-c0f6-bdbaf6fcf03f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>is_humor</th>\n",
              "      <th>humor_rating</th>\n",
              "      <th>humor_target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tweet1</td>\n",
              "      <td>Niveles de retraso mental: \\n\\n— Bajo.\\n— Medi...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tweet2</td>\n",
              "      <td>—Vamos Luke desenfunda tu sable, demuestra tu ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tweet3</td>\n",
              "      <td>- ¿Te ofrezco algo?, ¿Agua, café, mi corazón, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>2.6</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tweet4</td>\n",
              "      <td>No se porqué me hago la cabeza deooos</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tweet5</td>\n",
              "      <td>Quisiera saber que hago durante la siesta de l...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id                                               text  is_humor  \\\n",
              "0  tweet1  Niveles de retraso mental: \\n\\n— Bajo.\\n— Medi...         1   \n",
              "1  tweet2  —Vamos Luke desenfunda tu sable, demuestra tu ...         1   \n",
              "2  tweet3  - ¿Te ofrezco algo?, ¿Agua, café, mi corazón, ...         1   \n",
              "3  tweet4              No se porqué me hago la cabeza deooos         0   \n",
              "4  tweet5  Quisiera saber que hago durante la siesta de l...         0   \n",
              "\n",
              "   humor_rating humor_target  \n",
              "0           1.5          NaN  \n",
              "1           1.5          NaN  \n",
              "2           2.6          NaN  \n",
              "3           NaN          NaN  \n",
              "4           NaN          NaN  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWil13fvVpNw",
        "outputId": "b8abc0b2-6414-4e03-8c91-9e95aad80bae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.text.isnull().any() # no missing values in is_sarcastic column\n",
        "df.is_humor.isnull().any() # no missing values in headline column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7O67rqQ1Vuqb"
      },
      "outputs": [],
      "source": [
        "df['text'] = df.text.apply(lambda x:x.lower())  # convert all words in text into lower case \n",
        "df['text'] = df.text.apply(lambda x: ' '.join(word.strip(string.punctuation) for word in x.split()))  # remove all punctuation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OqtUdqB-iR-j",
        "outputId": "da402e56-8b7a-46d6-b9fb-983af1d324e8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>is_humor</th>\n",
              "      <th>humor_rating</th>\n",
              "      <th>humor_target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tweet1</td>\n",
              "      <td>niveles de retraso mental — bajo — medio — alt...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tweet2</td>\n",
              "      <td>—vamos luke desenfunda tu sable demuestra tu o...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tweet3</td>\n",
              "      <td>¿te ofrezco algo ¿agua café mi corazón mi vid...</td>\n",
              "      <td>1</td>\n",
              "      <td>2.6</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tweet4</td>\n",
              "      <td>no se porqué me hago la cabeza deooos</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tweet5</td>\n",
              "      <td>quisiera saber que hago durante la siesta de l...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id                                               text  is_humor  \\\n",
              "0  tweet1  niveles de retraso mental — bajo — medio — alt...         1   \n",
              "1  tweet2  —vamos luke desenfunda tu sable demuestra tu o...         1   \n",
              "2  tweet3   ¿te ofrezco algo ¿agua café mi corazón mi vid...         1   \n",
              "3  tweet4              no se porqué me hago la cabeza deooos         0   \n",
              "4  tweet5  quisiera saber que hago durante la siesta de l...         0   \n",
              "\n",
              "   humor_rating humor_target  \n",
              "0           1.5          NaN  \n",
              "1           1.5          NaN  \n",
              "2           2.6          NaN  \n",
              "3           NaN          NaN  \n",
              "4           NaN          NaN  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pOGN_I2hlaS4"
      },
      "outputs": [],
      "source": [
        "df = df.assign(CleanText=\"\", TokenizeText=\"\", NoStopwords=\"\", LemmaText=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBgRSltf4B2n",
        "outputId": "9708b8e4-1480-4fe0-d4ae-62106f11ebc3"
      },
      "outputs": [],
      "source": [
        "# case text as lowercase, remove punctuation, remove extra whitespace in string and on both sides of string\n",
        "\n",
        "df['CleanText'] = df['text'].str.replace(\"'\", '').str.replace('[^\\w\\s]', ' ').str.replace(\" \\d+\", \" \").str.replace(' +', ' ').str.strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "66u9u6zEXk_G"
      },
      "outputs": [],
      "source": [
        "def Tokenizacion(tweet):\n",
        "  tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
        "  tweet_tokens = tokenizer.tokenize(tweet)\n",
        "  return tweet_tokens\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UixdagnlLv1",
        "outputId": "d4368ac1-cb46-4f23-d062-42678c0d6f1f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\te512362\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "for i in range(len(df)):\n",
        "  df['TokenizeText'][i] = Tokenizacion(df['CleanText'][i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "l7TjBBaflPps"
      },
      "outputs": [],
      "source": [
        "stop_words_sp = set(stopwords.words('spanish'))\n",
        "stop_words_en = set(stopwords.words('english'))\n",
        "#Concatenar las stopwords aplicándose a una cuenta que genera contenido en inglés y español\n",
        "stop_words = stop_words_sp | stop_words_en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "oRAbGGdQlArD"
      },
      "outputs": [],
      "source": [
        "df['NoStopwords'] = df['TokenizeText'].apply(lambda x: [item for item in x if item not in stop_words])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "bFYTA90UlUtF",
        "outputId": "68a0a5a6-b070-46c1-d8c5-933508a4b909"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>is_humor</th>\n",
              "      <th>humor_rating</th>\n",
              "      <th>humor_target</th>\n",
              "      <th>CleanText</th>\n",
              "      <th>TokenizeText</th>\n",
              "      <th>NoStopwords</th>\n",
              "      <th>LemmaText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tweet1</td>\n",
              "      <td>niveles de retraso mental — bajo — medio — alt...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>niveles de retraso mental bajo medio alto elev...</td>\n",
              "      <td>[niveles, de, retraso, mental, bajo, medio, al...</td>\n",
              "      <td>[niveles, retraso, mental, bajo, medio, alto, ...</td>\n",
              "      <td>[niveles, retraso, mental, bajo, medio, alto, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tweet2</td>\n",
              "      <td>—vamos luke desenfunda tu sable demuestra tu o...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>vamos luke desenfunda tu sable demuestra tu od...</td>\n",
              "      <td>[vamos, luke, desenfunda, tu, sable, demuestra...</td>\n",
              "      <td>[vamos, luke, desenfunda, sable, demuestra, od...</td>\n",
              "      <td>[vamos, luke, desenfunda, sable, demuestra, od...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tweet3</td>\n",
              "      <td>¿te ofrezco algo ¿agua café mi corazón mi vid...</td>\n",
              "      <td>1</td>\n",
              "      <td>2.6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>te ofrezco algo agua café mi corazón mi vida e...</td>\n",
              "      <td>[te, ofrezco, algo, agua, café, mi, corazón, m...</td>\n",
              "      <td>[ofrezco, agua, café, corazón, vida, entera, a...</td>\n",
              "      <td>[ofrezco, agua, café, corazón, vida, enteron, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tweet4</td>\n",
              "      <td>no se porqué me hago la cabeza deooos</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>no se porqué me hago la cabeza deooos</td>\n",
              "      <td>[no, se, porqué, me, hago, la, cabeza, deooos]</td>\n",
              "      <td>[porqué, hago, cabeza, deooos]</td>\n",
              "      <td>[porqué, hago, cabeza, deooos]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tweet5</td>\n",
              "      <td>quisiera saber que hago durante la siesta de l...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>quisiera saber que hago durante la siesta de l...</td>\n",
              "      <td>[quisiera, saber, que, hago, durante, la, sies...</td>\n",
              "      <td>[quisiera, saber, hago, siesta, levanto, cansa...</td>\n",
              "      <td>[quisiera, saber, hago, siesta, levanto, cansa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id                                               text  is_humor  \\\n",
              "0  tweet1  niveles de retraso mental — bajo — medio — alt...         1   \n",
              "1  tweet2  —vamos luke desenfunda tu sable demuestra tu o...         1   \n",
              "2  tweet3   ¿te ofrezco algo ¿agua café mi corazón mi vid...         1   \n",
              "3  tweet4              no se porqué me hago la cabeza deooos         0   \n",
              "4  tweet5  quisiera saber que hago durante la siesta de l...         0   \n",
              "\n",
              "   humor_rating humor_target  \\\n",
              "0           1.5          NaN   \n",
              "1           1.5          NaN   \n",
              "2           2.6          NaN   \n",
              "3           NaN          NaN   \n",
              "4           NaN          NaN   \n",
              "\n",
              "                                           CleanText  \\\n",
              "0  niveles de retraso mental bajo medio alto elev...   \n",
              "1  vamos luke desenfunda tu sable demuestra tu od...   \n",
              "2  te ofrezco algo agua café mi corazón mi vida e...   \n",
              "3              no se porqué me hago la cabeza deooos   \n",
              "4  quisiera saber que hago durante la siesta de l...   \n",
              "\n",
              "                                        TokenizeText  \\\n",
              "0  [niveles, de, retraso, mental, bajo, medio, al...   \n",
              "1  [vamos, luke, desenfunda, tu, sable, demuestra...   \n",
              "2  [te, ofrezco, algo, agua, café, mi, corazón, m...   \n",
              "3     [no, se, porqué, me, hago, la, cabeza, deooos]   \n",
              "4  [quisiera, saber, que, hago, durante, la, sies...   \n",
              "\n",
              "                                         NoStopwords  \\\n",
              "0  [niveles, retraso, mental, bajo, medio, alto, ...   \n",
              "1  [vamos, luke, desenfunda, sable, demuestra, od...   \n",
              "2  [ofrezco, agua, café, corazón, vida, entera, a...   \n",
              "3                     [porqué, hago, cabeza, deooos]   \n",
              "4  [quisiera, saber, hago, siesta, levanto, cansa...   \n",
              "\n",
              "                                           LemmaText  \n",
              "0  [niveles, retraso, mental, bajo, medio, alto, ...  \n",
              "1  [vamos, luke, desenfunda, sable, demuestra, od...  \n",
              "2  [ofrezco, agua, café, corazón, vida, enteron, ...  \n",
              "3                     [porqué, hago, cabeza, deooos]  \n",
              "4  [quisiera, saber, hago, siesta, levanto, cansa...  "
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     C:\\Users\\te512362\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "JiK7paTflekw"
      },
      "outputs": [],
      "source": [
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "df['LemmaText'] = df['NoStopwords'].apply(lambda x: [wordnet_lemmatizer.lemmatize(y) for y in x]) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "WLE5yhPwrhyC"
      },
      "outputs": [],
      "source": [
        "df2 = df[df['humor_target'].isna() != True]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Kg3tcSbqs3u0"
      },
      "outputs": [],
      "source": [
        "topicos = np.unique(df2['humor_target'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "GLRWcC_KtuNS"
      },
      "outputs": [],
      "source": [
        "topics = []\n",
        "for element in topicos:\n",
        "    if element not in topics:\n",
        "        topics.append(element)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTQXXMSBuAD4",
        "outputId": "857c6f13-d0e3-4117-f69e-595025875f8f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "53"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(topics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "minfLZnfu3hQ"
      },
      "outputs": [],
      "source": [
        "dfLDA = df[df['humor_rating'].isna() != True]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN2Y3DYIyXeF",
        "outputId": "87f95c82-91db-45d5-86ee-bd9c530da7a9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\te512362\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "c:\\Users\\te512362\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "dfLDA['humor_rating'] = dfLDA['humor_rating'].round()\n",
        "dfLDA['humor_rating'] = np.array(dfLDA['humor_rating'], dtype=np.int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "bgox_C1xyiTZ",
        "outputId": "812b1459-0c4e-43b5-ee1c-037bff87851f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>is_humor</th>\n",
              "      <th>humor_rating</th>\n",
              "      <th>humor_target</th>\n",
              "      <th>CleanText</th>\n",
              "      <th>TokenizeText</th>\n",
              "      <th>NoStopwords</th>\n",
              "      <th>LemmaText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tweet1</td>\n",
              "      <td>niveles de retraso mental — bajo — medio — alt...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>niveles de retraso mental bajo medio alto elev...</td>\n",
              "      <td>[niveles, de, retraso, mental, bajo, medio, al...</td>\n",
              "      <td>[niveles, retraso, mental, bajo, medio, alto, ...</td>\n",
              "      <td>[niveles, retraso, mental, bajo, medio, alto, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tweet2</td>\n",
              "      <td>—vamos luke desenfunda tu sable demuestra tu o...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>vamos luke desenfunda tu sable demuestra tu od...</td>\n",
              "      <td>[vamos, luke, desenfunda, tu, sable, demuestra...</td>\n",
              "      <td>[vamos, luke, desenfunda, sable, demuestra, od...</td>\n",
              "      <td>[vamos, luke, desenfunda, sable, demuestra, od...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tweet3</td>\n",
              "      <td>¿te ofrezco algo ¿agua café mi corazón mi vid...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>te ofrezco algo agua café mi corazón mi vida e...</td>\n",
              "      <td>[te, ofrezco, algo, agua, café, mi, corazón, m...</td>\n",
              "      <td>[ofrezco, agua, café, corazón, vida, entera, a...</td>\n",
              "      <td>[ofrezco, agua, café, corazón, vida, enteron, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>tweet7</td>\n",
              "      <td>—buenas don pepe ¿me vende un litro de leche —...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>buenas don pepe me vende un litro de leche ent...</td>\n",
              "      <td>[buenas, don, pepe, me, vende, un, litro, de, ...</td>\n",
              "      <td>[buenas, pepe, vende, litro, leche, entera, si...</td>\n",
              "      <td>[buenas, pepe, vende, litro, leche, enteron, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>tweet13</td>\n",
              "      <td>20cosasquehacerantesdemorir enseñarles la dife...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20cosasquehacerantesdemorir enseñarles la dife...</td>\n",
              "      <td>[20cosasquehacerantesdemorir, enseñarles, la, ...</td>\n",
              "      <td>[20cosasquehacerantesdemorir, enseñarles, dife...</td>\n",
              "      <td>[20cosasquehacerantesdemorir, enseñarles, dife...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                                               text  is_humor  \\\n",
              "0    tweet1  niveles de retraso mental — bajo — medio — alt...         1   \n",
              "1    tweet2  —vamos luke desenfunda tu sable demuestra tu o...         1   \n",
              "2    tweet3   ¿te ofrezco algo ¿agua café mi corazón mi vid...         1   \n",
              "6    tweet7  —buenas don pepe ¿me vende un litro de leche —...         1   \n",
              "12  tweet13  20cosasquehacerantesdemorir enseñarles la dife...         1   \n",
              "\n",
              "    humor_rating humor_target  \\\n",
              "0              2          NaN   \n",
              "1              2          NaN   \n",
              "2              3          NaN   \n",
              "6              2          NaN   \n",
              "12             3          NaN   \n",
              "\n",
              "                                            CleanText  \\\n",
              "0   niveles de retraso mental bajo medio alto elev...   \n",
              "1   vamos luke desenfunda tu sable demuestra tu od...   \n",
              "2   te ofrezco algo agua café mi corazón mi vida e...   \n",
              "6   buenas don pepe me vende un litro de leche ent...   \n",
              "12  20cosasquehacerantesdemorir enseñarles la dife...   \n",
              "\n",
              "                                         TokenizeText  \\\n",
              "0   [niveles, de, retraso, mental, bajo, medio, al...   \n",
              "1   [vamos, luke, desenfunda, tu, sable, demuestra...   \n",
              "2   [te, ofrezco, algo, agua, café, mi, corazón, m...   \n",
              "6   [buenas, don, pepe, me, vende, un, litro, de, ...   \n",
              "12  [20cosasquehacerantesdemorir, enseñarles, la, ...   \n",
              "\n",
              "                                          NoStopwords  \\\n",
              "0   [niveles, retraso, mental, bajo, medio, alto, ...   \n",
              "1   [vamos, luke, desenfunda, sable, demuestra, od...   \n",
              "2   [ofrezco, agua, café, corazón, vida, entera, a...   \n",
              "6   [buenas, pepe, vende, litro, leche, entera, si...   \n",
              "12  [20cosasquehacerantesdemorir, enseñarles, dife...   \n",
              "\n",
              "                                            LemmaText  \n",
              "0   [niveles, retraso, mental, bajo, medio, alto, ...  \n",
              "1   [vamos, luke, desenfunda, sable, demuestra, od...  \n",
              "2   [ofrezco, agua, café, corazón, vida, enteron, ...  \n",
              "6   [buenas, pepe, vende, litro, leche, enteron, s...  \n",
              "12  [20cosasquehacerantesdemorir, enseñarles, dife...  "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfLDA.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MLFlow & LDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\te512362\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: MLflow support for Python 3.6 is deprecated and will be dropped in an upcoming release. At that point, existing Python 3.6 workflows that use MLflow will continue to work without modification, but Python 3.6 users will no longer get access to the latest MLflow features and bugfixes. We recommend that you upgrade to Python 3.7 or newer.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ],
      "source": [
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "track_uri = \"http://localhost:5000/\" # Esto puede ser que cambie por http://0.0.0.0:1234\n",
        "mlflow.set_tracking_uri(track_uri)\n",
        "mlflow.set_registry_uri(\"sqlite:////tmp/registry.db\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLflow Version: 1.23.1\n",
            "Tracking URI: http://localhost:5000/\n",
            "Nombre del experimento: LDA\n",
            "ID del experimento: 1\n"
          ]
        }
      ],
      "source": [
        "# Generando el experimento o cargandolo si existe\n",
        "experiment_name = \"LDA\"\n",
        "mlflow.set_experiment(experiment_name)\n",
        "\n",
        "# Cargando la información\n",
        "client = mlflow.tracking.MlflowClient()\n",
        "experiment_id = client.get_experiment_by_name(experiment_name).experiment_id\n",
        "\n",
        "\n",
        "# Vamos a ver si es cierto\n",
        "print(f\"MLflow Version: {mlflow.__version__}\")\n",
        "print(f\"Tracking URI: {mlflow.tracking.get_tracking_uri()}\")\n",
        "print(f\"Nombre del experimento: {experiment_name}\")\n",
        "print(f\"ID del experimento: {experiment_id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022/05/18 10:18:57 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n",
            "2022/05/18 10:18:57 WARNING mlflow.sklearn: Failed to infer model signature: the trained model does not specify a `predict` function, which is required in order to infer the signature\n"
          ]
        }
      ],
      "source": [
        "mlflow.sklearn.autolog()\n",
        "paramsVec = {\"analyzer\":\"word\",\"ngram_range\": (2,2)}\n",
        "\n",
        "# initialise the count vectorizer\n",
        "vectorizer = CountVectorizer(**(paramsVec))       \n",
        "\n",
        "with open('Vectorize.pkl', 'wb') as file:  \n",
        "    pickle.dump(vectorizer, file)          \n",
        "# join the processed data to be vectorised no_stopwords\n",
        "vectors = []\n",
        "for index, row in df.iterrows():\n",
        "    vectors.append(\", \".join(row[8]))\n",
        "vectorised = vectorizer.fit_transform(vectors)\n",
        "\n",
        "\n",
        "params = {'n_components':10,'random_state':10,'evaluate_every':-1,'n_jobs':-1}\n",
        "mlflow.log_params(paramsVec)\n",
        "mlflow.log_params(params)\n",
        "mlflow.log_artifact(\"Vectorize.pkl\", \"Vectores\")\n",
        "\n",
        "\n",
        "lda_model = LatentDirichletAllocation(**params)\n",
        "lda_output = lda_model.fit_transform(vectorised)\n",
        "\n",
        "mlflow.sklearn.log_model(lda_model, artifact_path=\"sklearn-model\")\n",
        "\n",
        "#metrics = mlflow.sklearn.eval_and_log_metrics(lda_model,vectorised, prefix=\"val_\")\n",
        "mlflow.end_run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>is_humor</th>\n",
              "      <th>humor_rating</th>\n",
              "      <th>humor_target</th>\n",
              "      <th>CleanText</th>\n",
              "      <th>TokenizeText</th>\n",
              "      <th>NoStopwords</th>\n",
              "      <th>LemmaText</th>\n",
              "      <th>Topic1</th>\n",
              "      <th>Topic2</th>\n",
              "      <th>Topic3</th>\n",
              "      <th>Topic4</th>\n",
              "      <th>Topic5</th>\n",
              "      <th>Topic6</th>\n",
              "      <th>Topic7</th>\n",
              "      <th>Topic8</th>\n",
              "      <th>Topic9</th>\n",
              "      <th>Topic10</th>\n",
              "      <th>Dominant_topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tweet1</td>\n",
              "      <td>niveles de retraso mental — bajo — medio — alt...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>niveles de retraso mental bajo medio alto elev...</td>\n",
              "      <td>[niveles, de, retraso, mental, bajo, medio, al...</td>\n",
              "      <td>[niveles, retraso, mental, bajo, medio, alto, ...</td>\n",
              "      <td>[niveles, retraso, mental, bajo, medio, alto, ...</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tweet2</td>\n",
              "      <td>—vamos luke desenfunda tu sable demuestra tu o...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>vamos luke desenfunda tu sable demuestra tu od...</td>\n",
              "      <td>[vamos, luke, desenfunda, tu, sable, demuestra...</td>\n",
              "      <td>[vamos, luke, desenfunda, sable, demuestra, od...</td>\n",
              "      <td>[vamos, luke, desenfunda, sable, demuestra, od...</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tweet3</td>\n",
              "      <td>¿te ofrezco algo ¿agua café mi corazón mi vid...</td>\n",
              "      <td>1</td>\n",
              "      <td>2.6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>te ofrezco algo agua café mi corazón mi vida e...</td>\n",
              "      <td>[te, ofrezco, algo, agua, café, mi, corazón, m...</td>\n",
              "      <td>[ofrezco, agua, café, corazón, vida, entera, a...</td>\n",
              "      <td>[ofrezco, agua, café, corazón, vida, enteron, ...</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tweet4</td>\n",
              "      <td>no se porqué me hago la cabeza deooos</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>no se porqué me hago la cabeza deooos</td>\n",
              "      <td>[no, se, porqué, me, hago, la, cabeza, deooos]</td>\n",
              "      <td>[porqué, hago, cabeza, deooos]</td>\n",
              "      <td>[porqué, hago, cabeza, deooos]</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tweet5</td>\n",
              "      <td>quisiera saber que hago durante la siesta de l...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>quisiera saber que hago durante la siesta de l...</td>\n",
              "      <td>[quisiera, saber, que, hago, durante, la, sies...</td>\n",
              "      <td>[quisiera, saber, hago, siesta, levanto, cansa...</td>\n",
              "      <td>[quisiera, saber, hago, siesta, levanto, cansa...</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>tweet6</td>\n",
              "      <td>la persona que te dice que no se arrepiente de...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>la persona que te dice que no se arrepiente de...</td>\n",
              "      <td>[la, persona, que, te, dice, que, no, se, arre...</td>\n",
              "      <td>[persona, dice, arrepiente, vida, toma, alcoho...</td>\n",
              "      <td>[persona, dice, arrepiente, vida, toma, alcoho...</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>tweet7</td>\n",
              "      <td>—buenas don pepe ¿me vende un litro de leche —...</td>\n",
              "      <td>1</td>\n",
              "      <td>2.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>buenas don pepe me vende un litro de leche ent...</td>\n",
              "      <td>[buenas, don, pepe, me, vende, un, litro, de, ...</td>\n",
              "      <td>[buenas, pepe, vende, litro, leche, entera, si...</td>\n",
              "      <td>[buenas, pepe, vende, litro, leche, enteron, s...</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>tweet8</td>\n",
              "      <td>meeee aburro</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>meeee aburro</td>\n",
              "      <td>[meee, aburro]</td>\n",
              "      <td>[meee, aburro]</td>\n",
              "      <td>[meee, aburro]</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.55</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>tweet9</td>\n",
              "      <td>macri le dijo las gordas que usar calzas está ...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>macri le dijo las gordas que usar calzas está ...</td>\n",
              "      <td>[macri, le, dijo, las, gordas, que, usar, calz...</td>\n",
              "      <td>[macri, dijo, gordas, usar, calzas, bien]</td>\n",
              "      <td>[macri, dijo, gordas, usar, calzas, bien]</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.02</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>tweet10</td>\n",
              "      <td>javier chicalito hernandez 7</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>javier chicalito hernandez</td>\n",
              "      <td>[javier, chicalito, hernandez]</td>\n",
              "      <td>[javier, chicalito, hernandez]</td>\n",
              "      <td>[javier, chicalito, hernandez]</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                               text  is_humor  \\\n",
              "0   tweet1  niveles de retraso mental — bajo — medio — alt...         1   \n",
              "1   tweet2  —vamos luke desenfunda tu sable demuestra tu o...         1   \n",
              "2   tweet3   ¿te ofrezco algo ¿agua café mi corazón mi vid...         1   \n",
              "3   tweet4              no se porqué me hago la cabeza deooos         0   \n",
              "4   tweet5  quisiera saber que hago durante la siesta de l...         0   \n",
              "5   tweet6  la persona que te dice que no se arrepiente de...         0   \n",
              "6   tweet7  —buenas don pepe ¿me vende un litro de leche —...         1   \n",
              "7   tweet8                                       meeee aburro         0   \n",
              "8   tweet9  macri le dijo las gordas que usar calzas está ...         0   \n",
              "9  tweet10                       javier chicalito hernandez 7         0   \n",
              "\n",
              "   humor_rating humor_target  \\\n",
              "0           1.5          NaN   \n",
              "1           1.5          NaN   \n",
              "2           2.6          NaN   \n",
              "3           NaN          NaN   \n",
              "4           NaN          NaN   \n",
              "5           NaN          NaN   \n",
              "6           2.5          NaN   \n",
              "7           NaN          NaN   \n",
              "8           NaN          NaN   \n",
              "9           NaN          NaN   \n",
              "\n",
              "                                           CleanText  \\\n",
              "0  niveles de retraso mental bajo medio alto elev...   \n",
              "1  vamos luke desenfunda tu sable demuestra tu od...   \n",
              "2  te ofrezco algo agua café mi corazón mi vida e...   \n",
              "3              no se porqué me hago la cabeza deooos   \n",
              "4  quisiera saber que hago durante la siesta de l...   \n",
              "5  la persona que te dice que no se arrepiente de...   \n",
              "6  buenas don pepe me vende un litro de leche ent...   \n",
              "7                                       meeee aburro   \n",
              "8  macri le dijo las gordas que usar calzas está ...   \n",
              "9                         javier chicalito hernandez   \n",
              "\n",
              "                                        TokenizeText  \\\n",
              "0  [niveles, de, retraso, mental, bajo, medio, al...   \n",
              "1  [vamos, luke, desenfunda, tu, sable, demuestra...   \n",
              "2  [te, ofrezco, algo, agua, café, mi, corazón, m...   \n",
              "3     [no, se, porqué, me, hago, la, cabeza, deooos]   \n",
              "4  [quisiera, saber, que, hago, durante, la, sies...   \n",
              "5  [la, persona, que, te, dice, que, no, se, arre...   \n",
              "6  [buenas, don, pepe, me, vende, un, litro, de, ...   \n",
              "7                                     [meee, aburro]   \n",
              "8  [macri, le, dijo, las, gordas, que, usar, calz...   \n",
              "9                     [javier, chicalito, hernandez]   \n",
              "\n",
              "                                         NoStopwords  \\\n",
              "0  [niveles, retraso, mental, bajo, medio, alto, ...   \n",
              "1  [vamos, luke, desenfunda, sable, demuestra, od...   \n",
              "2  [ofrezco, agua, café, corazón, vida, entera, a...   \n",
              "3                     [porqué, hago, cabeza, deooos]   \n",
              "4  [quisiera, saber, hago, siesta, levanto, cansa...   \n",
              "5  [persona, dice, arrepiente, vida, toma, alcoho...   \n",
              "6  [buenas, pepe, vende, litro, leche, entera, si...   \n",
              "7                                     [meee, aburro]   \n",
              "8          [macri, dijo, gordas, usar, calzas, bien]   \n",
              "9                     [javier, chicalito, hernandez]   \n",
              "\n",
              "                                           LemmaText  Topic1  Topic2  Topic3  \\\n",
              "0  [niveles, retraso, mental, bajo, medio, alto, ...    0.01    0.01    0.01   \n",
              "1  [vamos, luke, desenfunda, sable, demuestra, od...    0.01    0.01    0.94   \n",
              "2  [ofrezco, agua, café, corazón, vida, enteron, ...    0.92    0.01    0.01   \n",
              "3                     [porqué, hago, cabeza, deooos]    0.77    0.03    0.03   \n",
              "4  [quisiera, saber, hago, siesta, levanto, cansa...    0.01    0.01    0.01   \n",
              "5  [persona, dice, arrepiente, vida, toma, alcoho...    0.01    0.01    0.01   \n",
              "6  [buenas, pepe, vende, litro, leche, enteron, s...    0.93    0.01    0.01   \n",
              "7                                     [meee, aburro]    0.05    0.05    0.05   \n",
              "8          [macri, dijo, gordas, usar, calzas, bien]    0.02    0.02    0.02   \n",
              "9                     [javier, chicalito, hernandez]    0.03    0.03    0.70   \n",
              "\n",
              "   Topic4  Topic5  Topic6  Topic7  Topic8  Topic9  Topic10  Dominant_topic  \n",
              "0    0.90    0.01    0.01    0.01    0.01    0.01     0.01               4  \n",
              "1    0.01    0.01    0.01    0.01    0.01    0.01     0.01               3  \n",
              "2    0.01    0.01    0.01    0.01    0.01    0.01     0.01               1  \n",
              "3    0.03    0.03    0.03    0.03    0.03    0.03     0.03               1  \n",
              "4    0.01    0.01    0.89    0.01    0.01    0.01     0.01               6  \n",
              "5    0.01    0.01    0.01    0.90    0.01    0.01     0.01               7  \n",
              "6    0.01    0.01    0.01    0.01    0.01    0.01     0.01               1  \n",
              "7    0.05    0.05    0.05    0.05    0.05    0.05     0.55              10  \n",
              "8    0.02    0.02    0.02    0.02    0.02    0.85     0.02               9  \n",
              "9    0.03    0.03    0.03    0.03    0.03    0.03     0.03               3  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# column names\n",
        "topic_names = [\"Topic\" + str(i) for i in range(1, lda_model.n_components + 1)]\n",
        "\n",
        "# make the pandas dataframe\n",
        "\n",
        "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns = topic_names)\n",
        "\n",
        "# get dominant topic for each document\n",
        "\n",
        "dominant_topic = (np.argmax(df_document_topic.values, axis=1)+1)\n",
        "df_document_topic['Dominant_topic'] = dominant_topic\n",
        "\n",
        "# join to original dataframes\n",
        "\n",
        "dfLDA = pd.merge(df, df_document_topic, left_index = True, right_index = True, how = 'outer')\n",
        "display(dfLDA.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "Mq0o_eMzvRdB",
        "outputId": "2245cb71-f764-493e-9d54-c4972f8e6f52"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>topic</th>\n",
              "      <th>relevance_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>00 cosas</th>\n",
              "      <td>Topic10</td>\n",
              "      <td>1.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00 d3</th>\n",
              "      <td>Topic3</td>\n",
              "      <td>4.100014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00 dejar</th>\n",
              "      <td>Topic5</td>\n",
              "      <td>1.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00 dosogas</th>\n",
              "      <td>Topic10</td>\n",
              "      <td>1.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00 llegué</th>\n",
              "      <td>Topic9</td>\n",
              "      <td>1.100000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              topic  relevance_score\n",
              "00 cosas    Topic10         1.100000\n",
              "00 d3        Topic3         4.100014\n",
              "00 dejar     Topic5         1.100000\n",
              "00 dosogas  Topic10         1.100000\n",
              "00 llegué    Topic9         1.100000"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make the pandas dataframe\n",
        "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns=topic_names)\n",
        "\n",
        "# Get dominant topic for each document\n",
        "dominant_topic = np.argmax(df_document_topic.values, axis=1)\n",
        "df_document_topic['dominant_topic'] = dominant_topic\n",
        "\n",
        "# Topic-Keyword Matrix\n",
        "df_topic_keywords = pd.DataFrame(lda_model.components_)\n",
        "\n",
        "# Assign Column and Index\n",
        "df_topic_keywords.columns = vectorizer.get_feature_names()\n",
        "df_topic_keywords.index = topic_names\n",
        "\n",
        "df_topic_no = pd.DataFrame(df_topic_keywords.idxmax())\n",
        "df_scores = pd.DataFrame(df_topic_keywords.max())\n",
        "\n",
        "tmp = pd.merge(df_topic_no, df_scores, left_index=True, right_index=True)\n",
        "tmp.columns = ['topic', 'relevance_score']\n",
        "\n",
        "tmp.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "xsBC4nhgvX4h"
      },
      "outputs": [],
      "source": [
        "banned = ['Topic']\n",
        "tmp = tmp.replace(dict(zip(banned,['']*len(banned))),regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "BMVd6oTvvcbM",
        "outputId": "f7cfc0ef-3df3-4ec5-b74d-56985c89c153"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>topic</th>\n",
              "      <th>relevance_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>00 cosas</th>\n",
              "      <td>10</td>\n",
              "      <td>1.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00 d3</th>\n",
              "      <td>3</td>\n",
              "      <td>4.100014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00 dejar</th>\n",
              "      <td>5</td>\n",
              "      <td>1.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00 dosogas</th>\n",
              "      <td>10</td>\n",
              "      <td>1.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00 llegué</th>\n",
              "      <td>9</td>\n",
              "      <td>1.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00 vean</th>\n",
              "      <td>10</td>\n",
              "      <td>1.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0055florida seguime</th>\n",
              "      <td>9</td>\n",
              "      <td>1.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>01 cambió</th>\n",
              "      <td>1</td>\n",
              "      <td>1.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>01 compuesto</th>\n",
              "      <td>6</td>\n",
              "      <td>1.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>01 fb</th>\n",
              "      <td>1</td>\n",
              "      <td>1.100000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     topic  relevance_score\n",
              "00 cosas                10         1.100000\n",
              "00 d3                    3         4.100014\n",
              "00 dejar                 5         1.100000\n",
              "00 dosogas              10         1.100000\n",
              "00 llegué                9         1.100000\n",
              "00 vean                 10         1.100000\n",
              "0055florida seguime      9         1.100000\n",
              "01 cambió                1         1.100000\n",
              "01 compuesto             6         1.100000\n",
              "01 fb                    1         1.100000"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tmp[\"topic\"] = tmp[\"topic\"].astype(int) \n",
        "tmp.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zn2tX2gCveTT",
        "outputId": "0ae35ae4-f173-4c73-891a-53fa17b9934e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dominant_topic</th>\n",
              "      <th>topic_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11</td>\n",
              "      <td>[escribiendo escribiendo]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>[si va]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>[chistes humor]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>[cómo llama]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>[puede ser]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Dominant_topic                 topic_name\n",
              "0              11  [escribiendo escribiendo]\n",
              "1               4                    [si va]\n",
              "2               6            [chistes humor]\n",
              "3              10               [cómo llama]\n",
              "4               2                [puede ser]"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_topics = []\n",
        "\n",
        "for i in tmp['topic'].unique():    \n",
        "    tmp_1 = tmp.loc[tmp['topic'] == i].reset_index()\n",
        "    tmp_1 = tmp_1.sort_values('relevance_score', ascending=False).head(1)\n",
        "\n",
        "    tmp_1['topic'] = tmp_1['topic'] + 1\n",
        "    \n",
        "    tmp_2 = []\n",
        "    tmp_2.append(tmp_1['topic'].unique()[0])\n",
        "    tmp_2.append(list(tmp_1['index'].unique()))\n",
        "    all_topics.append(tmp_2)\n",
        "\n",
        "all_topics = pd.DataFrame(all_topics, columns=['Dominant_topic', 'topic_name'])\n",
        "all_topics.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iPMIwYYjvoJl",
        "outputId": "c4a4e639-79f1-43d7-8931-524b5fc4c3bf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th>topic_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>buen día</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cada vez</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>chistes humor</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>chistes rt</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cómo llama</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ja ja</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>puede ser</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>si va</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>va ser</th>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: [buen día, cada vez, chistes humor, chistes rt, cómo llama, ja ja, puede ser, si va, va ser]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "results = dfLDA.groupby(['Dominant_topic', 'is_humor']).count().reset_index()\n",
        "\n",
        "results = results.merge(all_topics, on='Dominant_topic')\n",
        "results['topic_name'] = results['topic_name'].apply(', '.join)\n",
        "\n",
        "graph_results = results[['topic_name', 'is_humor']]\n",
        "graph_results = graph_results.pivot(index='topic_name', columns='is_humor').reset_index()\n",
        "\n",
        "graph_results.set_index('topic_name', inplace=True)\n",
        "\n",
        "display(graph_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "Zwk8vnL4wvHs",
        "outputId": "f93e9813-1870-441a-f25b-8a35acf6a4a6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig = graph_results[[1]].plot.bar(rot=90, figsize=(10,5))\n",
        "fig.figure.savefig('sentiment_analysis.png', bbox_inches='tight', dpi=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbB9BmF1wyXJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ProyectoRP.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "7ea0809589b0323cf5406ab4f284eb1cb5f6416292f4a9799aa9889d8fe4b758"
    },
    "kernelspec": {
      "display_name": "Python 3.6.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
